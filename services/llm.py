"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ API"""
import logging
from openai import AsyncOpenAI

from config import Config

logger = logging.getLogger(__name__)


async def get_llm_response(messages: list, config: Config) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        
    Returns:
        –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM
    """
    try:
        client = AsyncOpenAI(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url
        )
        
        logger.info(f"LLM request: model={config.openai_model}, messages_count={len(messages)}")
        
        response = await client.chat.completions.create(
            model=config.openai_model,
            messages=messages,
            temperature=config.temperature,
            max_tokens=config.max_tokens,
            timeout=config.openai_timeout
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
        if not response.choices or not response.choices[0].message.content:
            logger.warning("Empty response from LLM")
            return "ü§î –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        
        answer = response.choices[0].message.content
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–¥–µ–ª–∏
        if answer:
            # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã DeepSeek –∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
            tokens_to_remove = [
                '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>',
                '<|begin_of_sentence|>',
                '<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>',
                '<|end_of_sentence|>',
                '<ÔΩúend‚ñÅof‚ñÅtextÔΩú>',
                '<|end_of_text|>',
            ]
            
            for token in tokens_to_remove:
                answer = answer.replace(token, '')
            
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ
            answer = answer.strip()
        
        logger.info(f"LLM response: length={len(answer)}")
        
        return answer
        
    except Exception as e:
        error_type = type(e).__name__
        logger.error(f"LLM error: {error_type} - {str(e)}")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
        if "rate" in str(e).lower() or "429" in str(e):
            return "‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
        elif "timeout" in str(e).lower():
            return "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞."
        elif "connection" in str(e).lower():
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–∏—Å—É."
        else:
            return "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

